{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "X = np.array([127.4, 364.4, 150, 128.7, 285.9, 200, 303.3, 315.7, 169.8, 104.9, \n",
    "              297.7, 256.4, 249.1, 323.1, 223, 235, 200])\n",
    "y = np.array([10.5, 21.4, 10, 9.6, 17.4, 12.5, 20, 21, 14.7, 10.1, 21.5, \n",
    "              16.6, 17.1, 20.7, 15.5, 13.5, 12.5])\n",
    "\n",
    "# Standardize the data\n",
    "X_mean = np.mean(X)\n",
    "X_std = np.std(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, beta_0, beta_1, alpha):\n",
    "    y_pred = beta_0 + beta_1 * X\n",
    "    error = y_pred - y\n",
    "    mse = np.mean(error ** 2)\n",
    "    lasso_penalty = alpha * (np.abs(beta_0) + np.abs(beta_1))\n",
    "    cost = mse + lasso_penalty\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, beta_0, beta_1, alpha):\n",
    "    y_pred = beta_0 + beta_1 * X\n",
    "    error = y_pred - y\n",
    "    gradient_beta_0 = np.mean(error) \n",
    "    gradient_beta_1 = np.mean(error * X) \n",
    "    return gradient_beta_0, gradient_beta_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: beta_0 = -3.9737652470575884e+273, beta_1 = -1.0171533001790196e+276, Cost = inf\n",
      "Iteration 200: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 300: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 400: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 500: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 600: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 700: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 800: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 900: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Iteration 1000: beta_0 = nan, beta_1 = nan, Cost = nan\n",
      "Lasso Regression: beta_0 = nan, beta_1 = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DK\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in square\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\DK\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in multiply\n",
      "  \"\"\"\n",
      "C:\\Users\\DK\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "beta_0 = 0\n",
    "beta_1 = 0\n",
    "alpha = 0.1  # regularization parameter\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Perform gradient descent\n",
    "for _ in range(iterations):\n",
    "    gradient_beta_0, gradient_beta_1 = compute_gradients(X_standardized, y, beta_0, beta_1, alpha)\n",
    "    \n",
    "    beta_0 -= learning_rate * gradient_beta_0\n",
    "    beta_1 -= learning_rate * gradient_beta_1\n",
    "    \n",
    "    # Calculate current cost (optional, for debugging)\n",
    "    current_cost = cost_function(X_standardized, y, beta_0, beta_1, alpha)\n",
    "    if current_cost < 0.2:\n",
    "        break\n",
    "    if (_ + 1) % 100 == 0:\n",
    "        print(f\"Iteration {_+1}: beta_0 = {beta_0}, beta_1 = {beta_1}, Cost = {current_cost}\")\n",
    "\n",
    "\n",
    "print(f\"Lasso Regression: beta_0 = {beta_0}, beta_1 = {beta_1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression: beta_0 = 3.356573092839179, beta_1 = 0.052749658759082454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the dataset\n",
    "X = np.array([127.4, 364.4, 150, 128.7, 285.9, 200, 303.3, 315.7, 169.8, 104.9, \n",
    "              297.7, 256.4, 249.1, 323.1, 223, 235, 200]).reshape(-1, 1)\n",
    "y = np.array([10.5, 21.4, 10, 9.6, 17.4, 12.5, 20, 21, 14.7, 10.1, 21.5, \n",
    "              16.6, 17.1, 20.7, 15.5, 13.5, 12.5])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X\n",
    "\n",
    "# Fit Lasso model\n",
    "alpha = 0.1  # regularization parameter\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# Get parameters\n",
    "beta_0 = lasso.intercept_\n",
    "beta_1 = lasso.coef_[0]\n",
    "\n",
    "print(f\"Lasso Regression: beta_0 = {beta_0}, beta_1 = {beta_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign([-5., 4.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "X = np.array([127.4, 364.4, 150, 128.7, 285.9, 200, 303.3, 315.7, 169.8, 104.9, \n",
    "              297.7, 256.4, 249.1, 323.1, 223, 235, 200])\n",
    "y = np.array([10.5, 21.4, 10, 9.6, 17.4, 12.5, 20, 21, 14.7, 10.1, 21.5, \n",
    "              16.6, 17.1, 20.7, 15.5, 13.5, 12.5])\n",
    "\n",
    "# Standardize the data\n",
    "X_mean = np.mean(X)\n",
    "X_std = np.std(X)\n",
    "X_standardized = (X - X_mean) / X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, beta_0, beta_1, alpha):\n",
    "    y_pred = beta_0 + beta_1 * X\n",
    "    error = y_pred - y\n",
    "    mse = np.mean(error ** 2)\n",
    "    ridge_penalty = alpha * ((beta_0)**2 + (beta_1)**2)\n",
    "    cost = mse + ridge_penalty\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, beta_0, beta_1, alpha):\n",
    "    y_pred = beta_0 + beta_1 * X\n",
    "    error = y_pred - y\n",
    "    gradient_beta_0 = np.mean(error) \n",
    "    gradient_beta_1 = np.mean(error * X) + alpha * np.sign(beta_1)\n",
    "    return gradient_beta_0, gradient_beta_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: beta_0 = 9.867520147006086, beta_1 = 2.457638722366988, Cost = 46.79659150675487\n",
      "Iteration 200: beta_0 = 13.47935164897548, beta_1 = 3.3568442482810745, Cost = 25.720610228785645\n",
      "Iteration 300: beta_0 = 14.801398789925758, beta_1 = 3.685982552217232, Cost = 25.62594613130217\n",
      "Iteration 400: beta_0 = 15.285310800201353, beta_1 = 3.8064578162096847, Cost = 26.6121979103655\n",
      "Iteration 500: beta_0 = 15.46243824629277, beta_1 = 3.8505556591543524, Cost = 27.10997806280498\n",
      "Iteration 600: beta_0 = 15.527272620089356, beta_1 = 3.866696895852488, Cost = 27.310507451391665\n",
      "Iteration 700: beta_0 = 15.551004097725102, beta_1 = 3.8726051105121506, Cost = 27.38636297154587\n",
      "Iteration 800: beta_0 = 15.559690586045996, beta_1 = 3.874767708156772, Cost = 27.41445750260902\n",
      "Iteration 900: beta_0 = 15.562870121703535, beta_1 = 3.8755592888358645, Cost = 27.424785083199556\n",
      "Iteration 1000: beta_0 = 15.56403393458442, beta_1 = 3.8758490329651414, Cost = 27.428571216670527\n",
      "Ridge Regression: beta_0 = 15.56403393458442, beta_1 = 3.8758490329651414\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "beta_0 = 0\n",
    "beta_1 = 0\n",
    "alpha = 0.1  # regularization parameter\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Perform gradient descent\n",
    "for _ in range(iterations):\n",
    "    gradient_beta_0, gradient_beta_1 = compute_gradients(X_standardized, y, beta_0, beta_1, alpha)\n",
    "    \n",
    "    beta_0 -= learning_rate * gradient_beta_0\n",
    "    beta_1 -= learning_rate * gradient_beta_1\n",
    "    \n",
    "    # Calculate current cost (optional, for debugging)\n",
    "    current_cost = cost_function(X_standardized, y, beta_0, beta_1, alpha)\n",
    "    if (_ + 1) % 100 == 0:\n",
    "        print(f\"Iteration {_+1}: beta_0 = {beta_0}, beta_1 = {beta_1}, Cost = {current_cost}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Ridge Regression: beta_0 = {beta_0}, beta_1 = {beta_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: beta_0 = 15.564705882352941, beta_1 = 3.876016321817417\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the dataset\n",
    "X = np.array([127.4, 364.4, 150, 128.7, 285.9, 200, 303.3, 315.7, 169.8, 104.9, \n",
    "              297.7, 256.4, 249.1, 323.1, 223, 235, 200]).reshape(-1, 1)\n",
    "y = np.array([10.5, 21.4, 10, 9.6, 17.4, 12.5, 20, 21, 14.7, 10.1, 21.5, \n",
    "              16.6, 17.1, 20.7, 15.5, 13.5, 12.5])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit Lasso model\n",
    "alpha = 0.1  # regularization parameter\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_scaled, y)\n",
    "\n",
    "# Get parameters\n",
    "beta_0 = lasso.intercept_\n",
    "beta_1 = lasso.coef_[0]\n",
    "\n",
    "print(f\"Ridge Regression: beta_0 = {beta_0}, beta_1 = {beta_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
